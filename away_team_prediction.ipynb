{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sys\n",
    "import bookie_package as bp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both_seasons_away = pd.read_pickle('df_both_seasons_essentials')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add avg Away Team Goal Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>...</th>\n",
       "      <th>HC</th>\n",
       "      <th>AC</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>HTGDIFF</th>\n",
       "      <th>ATGDIFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Leverkusen</td>\n",
       "      <td>Hertha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>M'gladbach</td>\n",
       "      <td>Paderborn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Wolfsburg</td>\n",
       "      <td>Schalke 04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Ein Frankfurt</td>\n",
       "      <td>FC Koln</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Freiburg</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Day  Month  Year       HomeTeam       AwayTeam  FTHG  FTAG  HS  AS  HST  \\\n",
       "139   18     12  2019     Leverkusen         Hertha   NaN   NaN NaN NaN  NaN   \n",
       "140   18     12  2019     M'gladbach      Paderborn   NaN   NaN NaN NaN  NaN   \n",
       "141   18     12  2019      Wolfsburg     Schalke 04   NaN   NaN NaN NaN  NaN   \n",
       "142   18     12  2019  Ein Frankfurt        FC Koln   NaN   NaN NaN NaN  NaN   \n",
       "143   18     12  2019       Freiburg  Bayern Munich   NaN   NaN NaN NaN  NaN   \n",
       "\n",
       "     ...  HC  AC  HF  AF  HY  AY  HR  AR  HTGDIFF  ATGDIFF  \n",
       "139  ... NaN NaN NaN NaN NaN NaN NaN NaN      NaN      NaN  \n",
       "140  ... NaN NaN NaN NaN NaN NaN NaN NaN      NaN      NaN  \n",
       "141  ... NaN NaN NaN NaN NaN NaN NaN NaN      NaN      NaN  \n",
       "142  ... NaN NaN NaN NaN NaN NaN NaN NaN      NaN      NaN  \n",
       "143  ... NaN NaN NaN NaN NaN NaN NaN NaN      NaN      NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_both_seasons_away.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_both_seasons = bp.averages.avg_goal_diff(df_both_seasons_away, 'AVGATGDIFF', 'AwayTeam', 'A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both_seasons = bp.averages.from_dict_value_to_df(d_both_seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both_seasons=df_both_seasons.sort_values(['Year', 'Month','Day'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ftag_per_team=bp.averages.avg_goals(df_both_seasons, 'AVGFTAG', 'AwayTeam', 'A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_both_seasons = bp.averages.from_dict_value_to_df(avg_ftag_per_team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both_seasons=df_both_seasons.sort_values(['Year', 'Month','Day'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>...</th>\n",
       "      <th>HF</th>\n",
       "      <th>AF</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>HTGDIFF</th>\n",
       "      <th>ATGDIFF</th>\n",
       "      <th>AVGATGDIFF</th>\n",
       "      <th>AVGFTAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Leverkusen</td>\n",
       "      <td>Hertha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.480000</td>\n",
       "      <td>1.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>M'gladbach</td>\n",
       "      <td>Paderborn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Wolfsburg</td>\n",
       "      <td>Schalke 04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>1.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Ein Frankfurt</td>\n",
       "      <td>FC Koln</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.625000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>Freiburg</td>\n",
       "      <td>Bayern Munich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Day  Month  Year       HomeTeam       AwayTeam  FTHG  FTAG  HS  AS  HST  \\\n",
       "139   18     12  2019     Leverkusen         Hertha   NaN   NaN NaN NaN  NaN   \n",
       "140   18     12  2019     M'gladbach      Paderborn   NaN   NaN NaN NaN  NaN   \n",
       "141   18     12  2019      Wolfsburg     Schalke 04   NaN   NaN NaN NaN  NaN   \n",
       "142   18     12  2019  Ein Frankfurt        FC Koln   NaN   NaN NaN NaN  NaN   \n",
       "143   18     12  2019       Freiburg  Bayern Munich   NaN   NaN NaN NaN  NaN   \n",
       "\n",
       "     ...  HF  AF  HY  AY  HR  AR  HTGDIFF  ATGDIFF  AVGATGDIFF   AVGFTAG  \n",
       "139  ... NaN NaN NaN NaN NaN NaN      NaN      NaN   -0.480000  1.320000  \n",
       "140  ... NaN NaN NaN NaN NaN NaN      NaN      NaN   -1.000000  1.142857  \n",
       "141  ... NaN NaN NaN NaN NaN NaN      NaN      NaN   -0.041667  1.458333  \n",
       "142  ... NaN NaN NaN NaN NaN NaN      NaN      NaN   -1.625000  0.750000  \n",
       "143  ... NaN NaN NaN NaN NaN NaN      NaN      NaN    1.000000  2.250000  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_both_seasons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Columns with previous ATGDIFF for each AwayTeam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_with_past_ATGDIFF=bp.averages.previous_data(df_both_seasons, 'AwayTeam', 'ATGDIFF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_ATGDIFF=bp.averages.from_dict_value_to_df(team_with_past_ATGDIFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>AF</th>\n",
       "      <th>AR</th>\n",
       "      <th>AS</th>\n",
       "      <th>AST</th>\n",
       "      <th>ATGDIFF</th>\n",
       "      <th>ATGDIFF_1</th>\n",
       "      <th>ATGDIFF_10</th>\n",
       "      <th>ATGDIFF_11</th>\n",
       "      <th>ATGDIFF_12</th>\n",
       "      <th>...</th>\n",
       "      <th>HC</th>\n",
       "      <th>HF</th>\n",
       "      <th>HR</th>\n",
       "      <th>HS</th>\n",
       "      <th>HST</th>\n",
       "      <th>HTGDIFF</th>\n",
       "      <th>HY</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leverkusen</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Ein Frankfurt</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Augsburg</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Union Berlin</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Werder Bremen</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AC    AF   AR    AS  AST  ATGDIFF  ATGDIFF_1  ATGDIFF_10  ATGDIFF_11  \\\n",
       "139  NaN   NaN  NaN   NaN  NaN      NaN        0.0         0.0        -2.0   \n",
       "117  1.0  15.0  0.0   9.0  3.0      0.0       -4.0        -2.0        -5.0   \n",
       "106  3.0  18.0  1.0   5.0  1.0     -4.0       -1.0        -5.0        -1.0   \n",
       "87   4.0   9.0  0.0   8.0  3.0     -1.0        0.0        -1.0        -1.0   \n",
       "68   5.0  11.0  0.0  11.0  2.0      0.0        4.0        -1.0         3.0   \n",
       "\n",
       "     ATGDIFF_12  ...    HC    HF   HR    HS  HST  HTGDIFF   HY       HomeTeam  \\\n",
       "139        -5.0  ...   NaN   NaN  NaN   NaN  NaN      NaN  NaN     Leverkusen   \n",
       "117        -1.0  ...  16.0  11.0  0.0  25.0  6.0      0.0  3.0  Ein Frankfurt   \n",
       "106        -1.0  ...   3.0   8.0  0.0  14.0  5.0      4.0  0.0       Augsburg   \n",
       "87          3.0  ...   1.0  14.0  0.0  16.0  6.0      1.0  1.0   Union Berlin   \n",
       "68          2.0  ...   7.0   8.0  0.0  15.0  5.0      0.0  1.0  Werder Bremen   \n",
       "\n",
       "     Month  Year  \n",
       "139     12  2019  \n",
       "117     12  2019  \n",
       "106     11  2019  \n",
       "87      11  2019  \n",
       "68      10  2019  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_team_with_past_ATGDIFF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_ATGDIFF = df_team_with_past_ATGDIFF.reindex(columns=[\n",
    "    'Day', 'Month', 'Year', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG',\n",
    "    'HTGDIFF', 'ATGDIFF', 'AVGATGDIFF','AVGFTAG', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR', 'ATGDIFF_1', 'ATGDIFF_2', 'ATGDIFF_3', 'ATGDIFF_4', 'ATGDIFF_5', 'ATGDIFF_6', 'ATGDIFF_7',\n",
    "    'ATGDIFF_8', 'ATGDIFF_9', 'ATGDIFF_10', 'ATGDIFF_11', 'ATGDIFF_12', 'ATGDIFF_13', 'ATGDIFF_14', 'ATGDIFF_15', 'ATGDIFF_16', 'ATGDIFF_17', 'ATGDIFF_18', 'ATGDIFF_19',\n",
    "    'ATGDIFF_20', 'ATGDIFF_21', 'ATGDIFF_22', 'ATGDIFF_23'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_ATGDIFF.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_with_past_AST=bp.averages.previous_data(df_team_with_past_ATGDIFF, 'AwayTeam', 'AST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_AST = bp.averages.from_dict_value_to_df(team_with_past_AST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "  df_team_with_past_AST = df_team_with_past_AST.reindex(columns=[ 'Day',\n",
    "    'Month',\n",
    "    'Year',\n",
    "    'HomeTeam',\n",
    "    'AwayTeam',\n",
    "    'FTHG',\n",
    "    'FTAG',\n",
    "    'HTGDIFF',\n",
    "    'ATGDIFF',\n",
    "    'AVGATGDIFF',\n",
    "    'AVGFTAG',\n",
    "    'HS',\n",
    "    'AS',\n",
    "    'HST',\n",
    "    'AST',\n",
    "    'HC',\n",
    "    'AC',\n",
    "    'HF',\n",
    "    'AF',\n",
    "    'HY',\n",
    "    'AY',\n",
    "    'HR',\n",
    "    'AR',\n",
    "    'ATGDIFF_1',\n",
    "    'ATGDIFF_2',\n",
    "    'ATGDIFF_3',\n",
    "    'ATGDIFF_4',\n",
    "    'ATGDIFF_5',\n",
    "    'ATGDIFF_6',\n",
    "    'ATGDIFF_7',\n",
    "    'ATGDIFF_8',\n",
    "    'ATGDIFF_9',\n",
    "    'ATGDIFF_10',\n",
    "    'ATGDIFF_11',\n",
    "    'ATGDIFF_12',\n",
    "    'ATGDIFF_13',\n",
    "    'ATGDIFF_14',\n",
    "    'ATGDIFF_15',\n",
    "    'ATGDIFF_16',\n",
    "    'ATGDIFF_17',\n",
    "    'ATGDIFF_18',\n",
    "    'ATGDIFF_19',\n",
    "    'ATGDIFF_20',\n",
    "    'ATGDIFF_21',\n",
    "    'ATGDIFF_22',\n",
    "    'ATGDIFF_23',\n",
    "    'AST_1',\n",
    "    'AST_2',\n",
    "    'AST_3',\n",
    "    'AST_4',\n",
    "    'AST_5',\n",
    "    'AST_6',\n",
    "    'AST_7',\n",
    "    'AST_8',\n",
    "    'AST_9',\n",
    "    'AST_10',\n",
    "    'AST_11',\n",
    "    'AST_12',\n",
    "    'AST_13',\n",
    "    'AST_14',\n",
    "    'AST_15',\n",
    "    'AST_16',\n",
    "    'AST_17',\n",
    "    'AST_18',\n",
    "    'AST_19',\n",
    "    'AST_20',\n",
    "    'AST_21',\n",
    "    'AST_22',\n",
    "    'AST_23',\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_with_past_FTAG = bp.averages.previous_data(df_team_with_past_AST, 'AwayTeam', 'FTAG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_FTAG = bp.averages.from_dict_value_to_df(team_with_past_FTAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "df_team_with_past_FTAG = df_team_with_past_FTAG.reindex(columns=[ 'Day',\n",
    "'Month',\n",
    "'Year',\n",
    "'HomeTeam',\n",
    "'AwayTeam',\n",
    "'FTHG',\n",
    "'FTAG',\n",
    "'HTGDIFF',\n",
    "'ATGDIFF',\n",
    "'AVGATGDIFF',\n",
    "'AVGFTAG',\n",
    "'HS',\n",
    "'AS',\n",
    "'HST',\n",
    "'AST',\n",
    "'HC',\n",
    "'AC',\n",
    "'HF',\n",
    "'AF',\n",
    "'HY',\n",
    "'AY',\n",
    "'HR',\n",
    "'AR',\n",
    "'ATGDIFF_1',\n",
    "'ATGDIFF_2',\n",
    "'ATGDIFF_3',\n",
    "'ATGDIFF_4',\n",
    "'ATGDIFF_5',\n",
    "'ATGDIFF_6',\n",
    "'ATGDIFF_7',\n",
    "'ATGDIFF_8',\n",
    "'ATGDIFF_9',\n",
    "'ATGDIFF_10',\n",
    "'ATGDIFF_11',\n",
    "'ATGDIFF_12',\n",
    "'ATGDIFF_13',\n",
    "'ATGDIFF_14',\n",
    "'ATGDIFF_15',\n",
    "'ATGDIFF_16',\n",
    "'ATGDIFF_17',\n",
    "'ATGDIFF_18',\n",
    "'ATGDIFF_19',\n",
    "'ATGDIFF_20',\n",
    "'ATGDIFF_21',\n",
    "'ATGDIFF_22',\n",
    "'ATGDIFF_23',\n",
    "'AST_1',\n",
    "'AST_2',\n",
    "'AST_3',\n",
    "'AST_4',\n",
    "'AST_5',\n",
    "'AST_6',\n",
    "'AST_7',\n",
    "'AST_8',\n",
    "'AST_9',\n",
    "'AST_10',\n",
    "'AST_11',\n",
    "'AST_12',\n",
    "'AST_13',\n",
    "'AST_14',\n",
    "'AST_15',\n",
    "'AST_16',\n",
    "'AST_17',\n",
    "'AST_18',\n",
    "'AST_19',\n",
    "'AST_20',\n",
    "'AST_21',\n",
    "'AST_22',\n",
    "'AST_23',\n",
    "'FTAG_1',\n",
    "'FTAG_2',\n",
    "'FTAG_3',\n",
    "'FTAG_4',\n",
    "'FTAG_5',\n",
    "'FTAG_6',\n",
    "'FTAG_7',\n",
    "'FTAG_8',\n",
    "'FTAG_9',\n",
    "'FTAG_10',\n",
    "'FTAG_11',\n",
    "'FTAG_12',\n",
    "'FTAG_13',\n",
    "'FTAG_14',\n",
    "'FTAG_15',\n",
    "'FTAG_16',\n",
    "'FTAG_17',\n",
    "'FTAG_18',\n",
    "'FTAG_19',\n",
    "'FTAG_20',\n",
    "'FTAG_21',\n",
    "'FTAG_22',\n",
    "'FTAG_23' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = []\n",
    "#for i in range(1,n_awaygames):\n",
    " #   a.append('FTAG_{}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_FTAG.sort_values(['Year', 'Month','Day'], ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_FTAG.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_FTAG = df_team_with_past_FTAG[['Day', 'Month', 'Year', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG',\n",
    "       'HTGDIFF', 'ATGDIFF', 'AVGATGDIFF', 'AVGFTAG', 'HS', 'AS', 'HST', 'AST',\n",
    "       'HC', 'AC', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR', 'ATGDIFF_1',\n",
    "       'ATGDIFF_2', 'ATGDIFF_3', 'ATGDIFF_4', 'ATGDIFF_5', 'ATGDIFF_6',\n",
    "       'ATGDIFF_7', 'ATGDIFF_8', 'ATGDIFF_9', 'ATGDIFF_10', 'AST_1', 'AST_2', 'AST_3', 'AST_4', 'AST_5',\n",
    "       'AST_6', 'AST_7', 'AST_8', 'AST_9', 'AST_10', 'FTAG_1', 'FTAG_2', 'FTAG_3',\n",
    "       'FTAG_4', 'FTAG_5', 'FTAG_6', 'FTAG_7', 'FTAG_8', 'FTAG_9', 'FTAG_10',\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_team_with_past_FTAG.to_excel('df_team_with_past_FTAG_away.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_team_with_past_FTAG.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_result.drop(['HomeTeam', 'AwayTeam'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features: (450, 51)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of features:', df_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels and Convert Data to Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "labels = np.array(df_result['FTAG'])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "df_result= df_result.drop(['Month','Day','Year','FTHG', 'FTAG', 'HTGDIFF', 'ATGDIFF', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR'], axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(df_result.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "df_result = np.array(df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    df_result, labels, test_size = 0.25,random_state = 42\n",
    ")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (337, 32)\n",
      "Training Labels Shape: (337,)\n",
      "Testing Features Shape: (113, 32)\n",
      "Testing Labels Shape: (113,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average baseline error:  0.99 Goals.\n"
     ]
    }
   ],
   "source": [
    "# The baseline predictions are the historical averages\n",
    "baseline_preds = train_features[:, feature_list.index('AVGFTAG')]\n",
    "# AVerage goals made by home team\n",
    "\n",
    "# Baseline errors, and display average baseline error\n",
    "baseline_errors = abs(baseline_preds - train_labels)\n",
    "print('Average baseline error: ', round(np.mean(baseline_errors), 2), 'Goals.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate model \n",
    "#rf = RandomForestRegressor(n_estimators= 1000, random_state=42)\n",
    "\n",
    "# Train the model on training data\n",
    "#rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = bp.prediction.random_forrest(train_features, train_labels, n_estimators=1000,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.98 Goals.\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'Goals.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zip(np.round(predictions,0), test_labels):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.22 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "err = errors/test_labels\n",
    "err[np.isnan(err)] = 0\n",
    "mape = err * 100\n",
    "mape[mape == inf] = 0\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a Single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[5]\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[5]\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree_away.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree_away.dot')\n",
    "# Write graph to a png file\n",
    "graph.write_png('tree_away.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The depth of this tree is: 20\n"
     ]
    }
   ],
   "source": [
    "print('The depth of this tree is:', tree.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Limit depth of tree to 2 levels\n",
    "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 4, random_state=42)\n",
    "rf_small.fit(train_features, train_labels)\n",
    "\n",
    "# Extract the small tree\n",
    "tree_small = rf_small.estimators_[5]\n",
    "\n",
    "# Save the tree as a png image\n",
    "export_graphviz(tree_small, out_file = 'small_tree_away.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "\n",
    "(graph, ) = pydot.graph_from_dot_file('small_tree_away.dot')\n",
    "\n",
    "graph.write_png('small_tree_away.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: AVGATGDIFF           Importance: 0.13928\n",
      "Variable: AVGFTAG              Importance: 0.08857\n",
      "Variable: AST_1                Importance: 0.06815\n",
      "Variable: AST_3                Importance: 0.0462\n",
      "Variable: ATGDIFF_1            Importance: 0.04422\n",
      "Variable: AST_7                Importance: 0.04215\n",
      "Variable: ATGDIFF_5            Importance: 0.04019\n",
      "Variable: AST_2                Importance: 0.03462\n",
      "Variable: ATGDIFF_3            Importance: 0.03295\n",
      "Variable: AST_4                Importance: 0.03227\n",
      "Variable: ATGDIFF_4            Importance: 0.03168\n",
      "Variable: AST_5                Importance: 0.03009\n",
      "Variable: AST_6                Importance: 0.02866\n",
      "Variable: ATGDIFF_2            Importance: 0.0272\n",
      "Variable: AST_9                Importance: 0.02561\n",
      "Variable: AST_10               Importance: 0.02386\n",
      "Variable: ATGDIFF_8            Importance: 0.0236\n",
      "Variable: ATGDIFF_6            Importance: 0.02176\n",
      "Variable: FTAG_2               Importance: 0.02023\n",
      "Variable: ATGDIFF_10           Importance: 0.01929\n",
      "Variable: FTAG_6               Importance: 0.01857\n",
      "Variable: FTAG_1               Importance: 0.01833\n",
      "Variable: ATGDIFF_7            Importance: 0.01813\n",
      "Variable: AST_8                Importance: 0.01798\n",
      "Variable: FTAG_3               Importance: 0.01684\n",
      "Variable: FTAG_5               Importance: 0.01509\n",
      "Variable: FTAG_10              Importance: 0.01498\n",
      "Variable: FTAG_4               Importance: 0.01296\n",
      "Variable: ATGDIFF_9            Importance: 0.01266\n",
      "Variable: FTAG_9               Importance: 0.01186\n",
      "Variable: FTAG_8               Importance: 0.01102\n",
      "Variable: FTAG_7               Importance: 0.01099\n"
     ]
    }
   ],
   "source": [
    "importances = list(rf.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 5)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_values = list(range(len(importances)))\n",
    "# # Make a bar chart\n",
    "# plt.bar(x_values, importances, orientation = 'vertical', color = 'r', edgecolor = 'k', linewidth = 1.2)\n",
    "# # Tick labels for x axis\n",
    "# plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "# # Axis labels and title\n",
    "# plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of features sorted from most to least important\n",
    "# sorted_importances = [importance[1] for importance in feature_importances]\n",
    "# sorted_features = [importance[0] for importance in feature_importances]\n",
    "# # Cumulative importances\n",
    "# cumulative_importances = np.cumsum(sorted_importances)\n",
    "# # Make a line graph\n",
    "# plt.plot(x_values, cumulative_importances, 'g-')\n",
    "# # Draw line at 95% of importance retained\n",
    "# plt.hlines(y = 0.95, xmin=0, xmax=len(sorted_importances), color = 'r', linestyles = 'dashed')\n",
    "# # Format x ticks and labels\n",
    "# plt.xticks(x_values, sorted_features, rotation = 'vertical')\n",
    "# # Axis labels and title\n",
    "# plt.xlabel('Variable'); plt.ylabel('Cumulative Importance'); plt.title('Cumulative Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find number of features for cumulative importance of 95%\n",
    "# # Add 1 because Python is zero-indexed\n",
    "# print('Number of features for 95% importance:', np.where(cumulative_importances > 0.95)[0][0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the names of the most important features\n",
    "# important_feature_names = [feature[0] for feature in feature_importances[0:5]]\n",
    "# # Find the columns of the most important features\n",
    "# important_indices = [feature_list.index(feature) for feature in important_feature_names]\n",
    "# # Create training and testing sets with only the important features\n",
    "# important_train_features = train_features[:, important_indices]\n",
    "# important_test_features = test_features[:, important_indices]\n",
    "# # Sanity check on operations\n",
    "# print('Important train features shape:', important_train_features.shape)\n",
    "# print('Important test features shape:', important_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_exp = RandomForestRegressor(n_estimators= 1000, random_state=100)\n",
    "# rf_exp.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the expanded model on only the important features\n",
    "# rf_exp.fit(important_train_features, train_labels);\n",
    "# # Make predictions on test data\n",
    "# predictions = rf_exp.predict(important_test_features)\n",
    "# # Performance metrics\n",
    "# errors = abs(predictions - test_labels)\n",
    "# print('Average absolute error:', round(np.mean(errors), 2), 'goals.')\n",
    "# # Calculate mean absolute percentage error (MAPE)\n",
    "\n",
    "# err = errors/test_labels\n",
    "# err[np.isnan(err)] = 0\n",
    "# mape = err * 100\n",
    "# mape[mape == inf] = 0\n",
    "\n",
    "# # Calculate and display accuracy\n",
    "# accuracy = 100 - np.mean(mape)\n",
    "# print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and Actual Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dates of training values\n",
    "# months = df_result[:, feature_list.index('Month')]\n",
    "# days = df_result[:, feature_list.index('Day')]\n",
    "# years = df_result[:, feature_list.index('Year')]\n",
    "\n",
    "# # List and then convert to datetime object\n",
    "# dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]\n",
    "# dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in dates]\n",
    "\n",
    "# # Dataframe with true values and dates\n",
    "# true_data = pd.DataFrame(data = {'date': dates, 'actual': labels})\n",
    "\n",
    "# # Dates of predictions\n",
    "# months = test_features[:, feature_list.index('Month')]\n",
    "# days = test_features[:, feature_list.index('Day')]\n",
    "# years = test_features[:, feature_list.index('Year')]\n",
    "\n",
    "# # Column of dates\n",
    "# test_dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]\n",
    "\n",
    "# # Convert to datetime objects\n",
    "# test_dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in test_dates]\n",
    "\n",
    "# # Dataframe with predictions and dates\n",
    "# predictions_data = pd.DataFrame(data = {'date': test_dates, 'prediction': predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(style='whitegrid', rc={'figure.figsize':(11.7,8.27)})\n",
    "# sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the actual values\n",
    "# plt.plot(true_data['date'], true_data['actual'], 'b-', label = 'actual')\n",
    "\n",
    "# # Plot the predicted values\n",
    "# plt.plot(predictions_data['date'], predictions_data['prediction'], 'ro', label = 'prediction')\n",
    "# plt.xticks(rotation = '60'); \n",
    "# plt.legend()\n",
    "\n",
    "# # Graph labels\n",
    "# plt.xlabel('Date'); plt.ylabel('ATHG'); plt.title('Actual and Predicted Values');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
